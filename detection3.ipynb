{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYYlWyos1wJcXR/zwQ6zSf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tuevu110405/AIO_Module_7/blob/feature%2Ftraining/detection3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Od5j4SqoqAbE"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO(\"yolov11l.pt\")\n",
        "\n",
        "video_path = \"samples/vietnam.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)"
      ],
      "metadata": {
        "id": "xKE55eU-qZ4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "video_name = video_path.split(\"/\")[-1]\n",
        "output_path = f\"run/{video_name.split('.')[0]}_tracked.mp4\"\n",
        "out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (width, height))"
      ],
      "metadata": {
        "id": "V6Mo80Ll_vMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Store the track history\n",
        "track_history = defaultdict(lambda: [])\n",
        "while cap.isOpened():\n",
        "    sucess, frame = cap.read()\n",
        "\n",
        "    if sucess:\n",
        "        results = model.track(frame, persist=True, show=False)\n",
        "        boxes = results[0].boxes.xywh.cpu()\n",
        "        try:\n",
        "            track_ids = results[0].boxes.id\n",
        "            if track_ids is not None:\n",
        "                track_ids = track_ids.int().cpu().tolist()\n",
        "\n",
        "            else:\n",
        "                track_ids = []\n",
        "\n",
        "        except AttributeError:\n",
        "            track_ids = []\n",
        "\n",
        "        annotated_frame = results[0].plot()\n",
        "\n",
        "        if track_ids:\n",
        "            for box, track_id in zip(boxes, track_ids):\n",
        "                x, y, w, h = box\n",
        "                track = track_history[track_id]\n",
        "                track.append((float(x), float(y)))\n",
        "\n",
        "                if len(track) > 120:\n",
        "                    track.pop(0)\n",
        "\n",
        "                points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))\n",
        "                cv2.polylines(annotated_frame, [points], isClosed=False, color=(230, 230, 230), thickness=4)\n",
        "\n",
        "\n",
        "\n",
        "        out.write(annotated_frame)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "print(f\"Video has been saved to {output_path}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1GBrrM5RB6kG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "from collections import defaultdict\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from ultralytics import YOLO\n",
        "from loguru import logger\n"
      ],
      "metadata": {
        "id": "mWeR74MK0IX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_config():\n",
        "    return {\n",
        "        \"model_path\": \"yolo11x.pt\",\n",
        "        \"track_history_length\": 120,\n",
        "        \"batch_size\" : 4,\n",
        "        \"track_color\" : (230, 230, 230),\n",
        "    }\n",
        "\n",
        "def initialize_video(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "    video_name = video_path.split(\"/\")[-1]\n",
        "    output_path = f\"run/{video_name.split('.')[0]}_tracked.mp4\"\n",
        "    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (width, height))\n",
        "\n",
        "    return cap, out, output_path"
      ],
      "metadata": {
        "id": "ssNJmfDU0igX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_track_history(\n",
        "        track_history,\n",
        "        last_seen,\n",
        "        track_ids,\n",
        "        frame_count,\n",
        "        batch_size,\n",
        "        frame_idx,\n",
        "        history_length,\n",
        "):\n",
        "\n",
        "    current_tracks = set(track_ids)\n",
        "    for track_id in list(track_history.keys()):\n",
        "        if track_id not in current_tracks:\n",
        "            last_seen[track_id] = frame_count - (batch_size - frame_idx - 1)\n",
        "\n",
        "        elif frame_count - last_seen[track_id] > history_length:\n",
        "            del track_history[track_id]\n",
        "            del last_seen[track_id]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jXPoVUrV4n78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_tracks(frame, boxes, track_ids, track_history, config):\n",
        "    if not track_ids:\n",
        "        return frame\n",
        "\n",
        "    for box, track_id in zip(boxes, track_ids):\n",
        "        x, y, w, h = box\n",
        "        track = track_history[track_id]\n",
        "        track.append((float(x), float(y)))\n",
        "        if len(track) > config[\"track_history_length\"]:\n",
        "            track.pop(0)\n",
        "\n",
        "        points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))\n",
        "        cv2.polylines(frame,\n",
        "                      [points],\n",
        "                      isClosed=False,\n",
        "                      color = config[\"track_color\"],\n",
        "                      thickness = config[\"line_thickness\"])\n",
        "\n",
        "    return frame\n",
        "\n"
      ],
      "metadata": {
        "id": "2iFaWkUy8P2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_batch(model, batch_frames, track_history, frame_count, config):\n",
        "    results = model.track(\n",
        "        batch_frames,\n",
        "        persist = True,\n",
        "        tracker = \"botsort.yaml\",\n",
        "        show = False,\n",
        "        verbose = False,\n",
        "        iou = 0.5,\n",
        "    )\n",
        "\n",
        "    processed_frames = []\n",
        "    for frame_idx, result in enumerate(results):\n",
        "        boxes = result.boxes.xywh.cpu()\n",
        "        track_ids = (\n",
        "            result.boxes.id.int().cpu().tolist() if result.boxes.id is not None\n",
        "    else []\n",
        "        )\n",
        "\n",
        "        update_track_history(\n",
        "            track_history,\n",
        "            last_seen,\n",
        "            track_ids,\n",
        "            frame_count,\n",
        "            len(batch_frames),\n",
        "            frame_idx,\n",
        "            config[\"track_history_length\"],\n",
        "        )\n",
        "\n",
        "        annotated_frame = result.plot(font_size = 4, line_width = 2)\n",
        "        annotated_frame = draw_tracks(\n",
        "            annotated_frame, boxes, track_ids, track_history, config\n",
        "        )\n",
        "        processed_frames.append(annotated_frame)\n",
        "\n",
        "    return processed_frames\n"
      ],
      "metadata": {
        "id": "H0vn9w-LA8bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(video_path):\n",
        "    CONFIG = load_config()\n",
        "    model(CONFIG.get(\"model_path\", \"yolo11x.pt\"))\n",
        "\n",
        "    cap, out, output_path = initialize_video(video_path)\n",
        "    track_history = defaultdict(int)\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    with tqdm(\n",
        "        total=total_frames,\n",
        "        desc = \"Processing frames\",\n",
        "        colour = \"green\",\n",
        "    ) as pbar:\n",
        "        frame_count = 0\n",
        "        batch_frames = []\n",
        "\n",
        "        while cap.isOpened():\n",
        "            success, frame = cap.read()\n",
        "\n",
        "            if not success:\n",
        "                break\n",
        "\n",
        "            batch_frames.append(frame)\n",
        "            frame_count += 1\n",
        "\n",
        "            if len(batch_frames) == CONFIG[\"batch_size\"] or frame_count == total_frames:\n",
        "                try:\n",
        "                    processed_frames = process_batch(\n",
        "                        model,\n",
        "                        batch_frames,\n",
        "                        track_history,\n",
        "                        last_seen,\n",
        "                        frame_count,\n",
        "                        CONFIG,\n",
        "                    )\n",
        "                    for frame in processed_frames:\n",
        "                        out.write(frame)\n",
        "                        pbar.update(1)\n",
        "                    batch_frames = []\n",
        "\n",
        "                except Exception as e:\n",
        "                    logger.error(\n",
        "                        f\"Error when handling frames {frame_count - len(batch_frames) + 1} to {frame_count} : {str(e)}\"\n",
        "                    )\n",
        "                    batch_frames = []\n",
        "                    continue\n",
        "\n",
        "    try:\n",
        "        cap.release()\n",
        "        out.release()\n",
        "        cv2.destroyAllWindows()\n",
        "        logger.info(f\"{output_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"{str(e)}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--video-path\", type=str, default = \"samples/vietnam-2.mp4\")\n",
        "    args = parser.parser_args()\n",
        "    main(args.video_path)\n"
      ],
      "metadata": {
        "id": "r9Peo0DhJMXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Object counting"
      ],
      "metadata": {
        "id": "VRawuj9zrv9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from ultralytics import solutions"
      ],
      "metadata": {
        "id": "hHwduXiDrvDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(\"samples/highway.mp4\")\n",
        "assert cap.isOpened(), \"Error reading video file\"\n",
        "w, h, fps = (\n",
        "    int(cap.get(x))\n",
        "    for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS)\n",
        ")"
      ],
      "metadata": {
        "id": "w1RLwToCxhWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define region points\n",
        "#region_points = [(20, 400), (1080, 400)]\n",
        "region_points = [\n",
        "    (430, 700),\n",
        "    (1600, 700),\n",
        "    (1600, 1080),\n",
        "    (430, 1080),\n",
        "]"
      ],
      "metadata": {
        "id": "-2k5UmghyD4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_writer = cv2.VideoWriter(\n",
        "    \"./run/highway_tracked.mp4\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h)\n",
        ")\n"
      ],
      "metadata": {
        "id": "V4w6dk75yjjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counter = solutions.ObjectCounter(\n",
        "    show = False,\n",
        "    region = region_points,\n",
        "    model = \"yolo11x.pt\"\n",
        ")"
      ],
      "metadata": {
        "id": "6lem2nbRyxOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while cap.isOpened():\n",
        "    sucess, im0 = cap.read()\n",
        "    if not sucess:\n",
        "        print(\n",
        "            \"Video frame is empty or video processing has been sucessfully completed.\"\n",
        "        )\n",
        "        break\n",
        "    im0 = counter.count(im0)\n",
        "    video_writer.write(im0)\n",
        "\n",
        "cap.release()\n",
        "video_writer.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "RgnE6Rnjzeq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLOWorld\n",
        "from ultralytics.engine.results import Boxes\n",
        "\n",
        "from src.utils import save_detection_results"
      ],
      "metadata": {
        "id": "qfe5PEgy0X_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLOWorld(\"yolov8s-world.pt\")"
      ],
      "metadata": {
        "id": "d1I4msPZ0yWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.set_classes([\"bus\"])"
      ],
      "metadata": {
        "id": "DPRBMwUq09Da"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results: Boxes = model.predict(\"samples/bus.jpg\")"
      ],
      "metadata": {
        "id": "rUBZsqoC1Hjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_detection_results(results)"
      ],
      "metadata": {
        "id": "lIWPEFu31WNK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}